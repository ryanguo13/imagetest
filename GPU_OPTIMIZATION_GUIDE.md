# GPUä¼˜åŒ–æŒ‡å— - æ¦¨å¹²ä½ çš„æ˜¾å¡æ€§èƒ½ ğŸš€

## é—®é¢˜è¯Šæ–­

ä½ é‡åˆ°çš„GPUåˆ©ç”¨ç‡åªæœ‰20%çš„é—®é¢˜ï¼Œä¸»è¦åŸå› æ˜¯ï¼š

1. **æ¨¡å‹å¤ªå°**: `base_channels=32`, `num_blocks=4` è®¡ç®—é‡ä¸è¶³
2. **æ•°æ®åŠ è½½ç“¶é¢ˆ**: `num_workers=0` æ²¡æœ‰å¹¶è¡Œæ•°æ®åŠ è½½ï¼ŒCPUæˆä¸ºç“¶é¢ˆ
3. **batch_sizeä¿å®ˆ**: è¿˜æœ‰æå‡ç©ºé—´
4. **ç¼ºå°‘GPUä¼˜åŒ–**: æ²¡æœ‰æ··åˆç²¾åº¦è®­ç»ƒã€æ¨¡å‹ç¼–è¯‘ç­‰ä¼˜åŒ–

## ğŸ¯ ä¸€é”®ä¼˜åŒ–è§£å†³æ–¹æ¡ˆ

### 1. å¿«é€Ÿä¼˜åŒ–ï¼ˆæ¨èï¼‰

```bash
# å®‰è£…åŸºç¡€ä¾èµ–
pip install psutil

# ä¸€é”®ä¼˜åŒ–é…ç½®ï¼ˆå·²ä¿®å¤å…¼å®¹æ€§é—®é¢˜ï¼‰
python optimize_gpu.py --config configs/lightweight_config.yaml

# ä½¿ç”¨ä¼˜åŒ–åçš„é…ç½®è®­ç»ƒ
python src/main.py --config configs/lightweight_gpu_optimized.yaml
```

> **ğŸ’¡ æ³¨æ„:** å·¥å…·å·²ä¿®å¤å…¼å®¹æ€§é—®é¢˜ï¼Œå³ä½¿åœ¨æŸäº›ç¯å¢ƒä¸‹æ— æ³•ä½¿ç”¨é«˜çº§GPUç›‘æ§ï¼Œä¹Ÿä¼šè‡ªåŠ¨é™çº§åˆ°åŸºç¡€ä¼˜åŒ–æ¨¡å¼ã€‚

### 2. å®Œæ•´ä¼˜åŒ–æµç¨‹

```bash
# Step 1: ç”ŸæˆåŸºç¡€ä¼˜åŒ–é…ç½®
python optimize_gpu.py --config configs/lightweight_config.yaml

# Step 2: è¿è¡Œæ€§èƒ½åŸºå‡†æµ‹è¯•ï¼Œè‡ªåŠ¨æœç´¢æœ€ä¼˜batch size
python optimize_gpu.py --config configs/lightweight_gpu_optimized.yaml --benchmark

# Step 3: è®­ç»ƒæ—¶å®æ—¶ç›‘æ§GPUä½¿ç”¨æƒ…å†µ
python optimize_gpu.py --monitor 300 &  # åå°ç›‘æ§5åˆ†é’Ÿ
python src/main.py --config configs/lightweight_gpu_optimized_optimized.yaml
```

## ğŸ“Š ä¼˜åŒ–åçš„é…ç½®å¯¹æ¯”

| å‚æ•° | åŸå§‹é…ç½® | ä¼˜åŒ–é…ç½® | æå‡æ•ˆæœ |
|------|----------|----------|----------|
| `batch_size` | 16 | 32+ | ğŸš€ è®¡ç®—é‡ç¿»å€ |
| `base_channels` | 32 | 96+ | ğŸš€ æ¨¡å‹å¤æ‚åº¦3å€ |
| `num_blocks` | 4 | 8+ | ğŸš€ ç½‘ç»œæ·±åº¦ç¿»å€ |
| `num_workers` | 0 | 8+ | ğŸš€ æ•°æ®å¹¶è¡ŒåŠ è½½ |
| `patch_size` | 128 | 192+ | ğŸš€ æ›´å¤§è¾“å…¥å°ºå¯¸ |
| `use_mixed_precision` | âŒ | âœ… | ğŸ’¡ å†…å­˜æ•ˆç‡æå‡ |
| `use_perceptual` | âŒ | âœ… | ğŸ’¡ å¢åŠ è®¡ç®—é‡ |
| `compile_model` | âŒ | âœ… | ğŸ’¡ æ¨ç†ä¼˜åŒ– |

## ğŸ›  æ‰‹åŠ¨è°ƒä¼˜ç­–ç•¥

å¦‚æœä¸€é”®ä¼˜åŒ–è¿˜ä¸å¤Ÿï¼Œå¯ä»¥æ‰‹åŠ¨è°ƒä¼˜ï¼š

### 1. å¢å¤§batch_size
```yaml
batch_size: 64  # ä»32é€æ­¥å¢åŠ åˆ°64ã€128ç­‰ï¼Œç›´åˆ°æ˜¾å­˜ä¸å¤Ÿ
```

### 2. å¢åŠ æ¨¡å‹å¤æ‚åº¦
```yaml
base_channels: 128    # ä»96å¢åŠ åˆ°128
num_blocks: 12        # ä»8å¢åŠ åˆ°12
```

### 3. ä¼˜åŒ–æ•°æ®åŠ è½½
```yaml
num_workers: 12       # CPUæ ¸å¿ƒæ•°
pin_memory: true      # å›ºå®šå†…å­˜ï¼ŒåŠ é€ŸGPUä¼ è¾“
persistent_workers: true  # ä¿æŒworkerè¿›ç¨‹
prefetch_factor: 4    # é¢„åŠ è½½æ‰¹æ¬¡
```

### 4. å¯ç”¨æ‰€æœ‰GPUä¼˜åŒ–
```yaml
use_mixed_precision: true   # æ··åˆç²¾åº¦è®­ç»ƒ
compile_model: true         # PyTorch 2.0æ¨¡å‹ç¼–è¯‘
grad_clip: 1.0             # æ¢¯åº¦è£å‰ªé˜²æ­¢çˆ†ç‚¸
```

## ğŸ“ˆ é¢„æœŸæ€§èƒ½æå‡

æ ¹æ®ä½ çš„GPUè§„æ ¼ï¼Œé¢„æœŸæ€§èƒ½æå‡ï¼š

### RTX 4090 (24GB)
- **GPUåˆ©ç”¨ç‡**: 20% â†’ 85%+
- **è®­ç»ƒé€Ÿåº¦**: 3-5å€æå‡
- **å»ºè®®é…ç½®**: `batch_size: 64`, `base_channels: 128`

### RTX 4080 (16GB) 
- **GPUåˆ©ç”¨ç‡**: 20% â†’ 80%+
- **è®­ç»ƒé€Ÿåº¦**: 2-4å€æå‡
- **å»ºè®®é…ç½®**: `batch_size: 48`, `base_channels: 96`

### RTX 4070 (12GB)
- **GPUåˆ©ç”¨ç‡**: 20% â†’ 75%+
- **è®­ç»ƒé€Ÿåº¦**: 2-3å€æå‡
- **å»ºè®®é…ç½®**: `batch_size: 32`, `base_channels: 96`

## ğŸ” å®æ—¶ç›‘æ§å·¥å…·

### è®­ç»ƒæœŸé—´ç›‘æ§
```bash
# åœ¨å¦ä¸€ä¸ªç»ˆç«¯è¿è¡Œï¼Œå®æ—¶æ˜¾ç¤ºGPUçŠ¶æ€
python optimize_gpu.py --monitor 0  # 0è¡¨ç¤ºæŒç»­ç›‘æ§
```

### ç›‘æ§è¾“å‡ºç¤ºä¾‹
```
ğŸ¯ GPUåˆ©ç”¨ç‡:  87% | æ˜¾å­˜ä½¿ç”¨:  78% (9.4GB)

ğŸ“Š ç›‘æ§æ€»ç»“:
å¹³å‡GPUåˆ©ç”¨ç‡: 85.3%
å¹³å‡æ˜¾å­˜ä½¿ç”¨: 76.2%
å³°å€¼æ˜¾å­˜ä½¿ç”¨: 9.8GB
âœ… GPUåˆ©ç”¨ç‡è‰¯å¥½!
```

## âš¡ è¿›é˜¶ä¼˜åŒ–æŠ€å·§

### 1. è‡ªåŠ¨æœç´¢æœ€ä¼˜batch size
```python
from utils.gpu_optimizer import BatchSizeOptimizer

# ä¼šè‡ªåŠ¨æµ‹è¯•ä¸åŒbatch sizeï¼Œæ‰¾åˆ°æœ€ä¼˜é…ç½®
optimizer = BatchSizeOptimizer(model, config)
optimal_batch_size, stats = optimizer.find_optimal_batch_size(
    sample_data, target_gpu_util=85.0
)
```

### 2. æ ¹æ®GPUè‡ªåŠ¨ç”Ÿæˆé…ç½®
```python
from utils.gpu_optimizer import auto_optimize_config

# è‡ªåŠ¨æ£€æµ‹GPUå‹å·å’Œæ˜¾å­˜ï¼Œç”Ÿæˆæœ€ä¼˜é…ç½®
optimized_config = auto_optimize_config(
    'configs/lightweight_config.yaml',
    'configs/auto_optimized.yaml'
)
```

### 3. å¤šGPUè®­ç»ƒï¼ˆå¦‚æœæœ‰å¤šå¼ å¡ï¼‰
```bash
# ä½¿ç”¨DistributedDataParallel
python -m torch.distributed.launch --nproc_per_node=2 src/main.py --config configs/optimized_config.yaml
```

## ğŸš¨ å¸¸è§é—®é¢˜è§£å†³

### Q: ä¼˜åŒ–åå‡ºç°OOM (Out of Memory)
**A**: é€æ­¥å‡å°batch_sizeï¼Œä»64â†’48â†’32â†’16ï¼Œç›´åˆ°ä¸æŠ¥é”™

### Q: GPUåˆ©ç”¨ç‡ä»ç„¶ä¸é«˜
**A**: 
1. å¢å¤§`base_channels`å’Œ`num_blocks`
2. æ£€æŸ¥æ•°æ®åŠ è½½æ˜¯å¦æ˜¯ç“¶é¢ˆï¼ˆ`num_workers`æ˜¯å¦è¶³å¤Ÿï¼‰
3. ç¡®ä¿ä½¿ç”¨äº†æ··åˆç²¾åº¦è®­ç»ƒ

### Q: è®­ç»ƒä¸ç¨³å®šæˆ–lossçˆ†ç‚¸
**A**: 
1. å¯ç”¨æ¢¯åº¦è£å‰ªï¼š`grad_clip: 1.0`
2. é™ä½å­¦ä¹ ç‡ï¼š`lr: 0.0001`
3. ä½¿ç”¨warmupç­–ç•¥

### Q: æ•°æ®åŠ è½½æ…¢
**A**: 
1. å¢å¤§`num_workers`ï¼ˆå»ºè®®è®¾ä¸ºCPUæ ¸å¿ƒæ•°ï¼‰
2. å¯ç”¨`pin_memory: true`
3. ä½¿ç”¨SSDå­˜å‚¨æ•°æ®

## ğŸ“ é…ç½®æ–‡ä»¶ç¤ºä¾‹

### é«˜æ€§èƒ½é…ç½® (RTX 4090)
```yaml
# configs/high_performance.yaml
batch_size: 64
base_channels: 128
num_blocks: 12
patch_size: 256
num_workers: 12
use_mixed_precision: true
use_perceptual: true
pin_memory: true
persistent_workers: true
compile_model: true
```

### å¹³è¡¡é…ç½® (RTX 4070)
```yaml
# configs/balanced.yaml  
batch_size: 32
base_channels: 96
num_blocks: 8
patch_size: 192
num_workers: 8
use_mixed_precision: true
use_perceptual: true
pin_memory: true
```

### è½»é‡é…ç½® (GTX 1080)
```yaml
# configs/lightweight_optimized.yaml
batch_size: 16
base_channels: 64
num_blocks: 6
patch_size: 128
num_workers: 6
use_mixed_precision: true
use_perceptual: false
```

## ğŸ‰ æ€»ç»“

é€šè¿‡è¿™äº›ä¼˜åŒ–ï¼Œä½ çš„GPUåˆ©ç”¨ç‡åº”è¯¥èƒ½ä»20%æå‡åˆ°80%+ï¼Œè®­ç»ƒé€Ÿåº¦æå‡2-5å€ï¼

å…³é”®ä¼˜åŒ–ç‚¹ï¼š
1. âœ… **å¢å¤§batch_size** - æœ€ç›´æ¥æœ‰æ•ˆ
2. âœ… **å¢åŠ æ¨¡å‹å¤æ‚åº¦** - æä¾›è¶³å¤Ÿè®¡ç®—é‡
3. âœ… **å¹¶è¡Œæ•°æ®åŠ è½½** - æ¶ˆé™¤IOç“¶é¢ˆ
4. âœ… **æ··åˆç²¾åº¦è®­ç»ƒ** - æé«˜å†…å­˜æ•ˆç‡
5. âœ… **æ¨¡å‹ç¼–è¯‘ä¼˜åŒ–** - PyTorch 2.0åŠ é€Ÿ

ç°åœ¨å°±è¯•è¯•è¿™ä¸ªå‘½ä»¤å¼€å§‹ä¼˜åŒ–å§ï¼š
```bash
python optimize_gpu.py --config configs/lightweight_config.yaml --benchmark
``` 